{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c134fba4",
   "metadata": {},
   "source": [
    "### Main pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea480a8b",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83dd6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Clicked at: (63, 95)\n",
    "# Clicked at: (174, 107)\n",
    "# Clicked at: (115, 139)\n",
    "# Clicked at: (234, 138)\n",
    "# Clicked at: (92, 185)\n",
    "# Clicked at: (178, 198)\n",
    "# Clicked at: (163, 211)\n",
    "# Clicked at: (117, 258)\n",
    "# Clicked at: (240, 255)\n",
    "# Clicked at: (103, 291)\n",
    "# Clicked at: (178, 288)\n",
    "# pixel_coordinates = [[202,63], [323,76], [256,112], [388,108], [232,161], [323,178], [308,190], [259,240], [388,239], [243,276], [323,274]]\n",
    "# pixel_coordinates = [[196,92], [326,106], [255,146], [398,142], [229,199], [327,216], [310,230], [259,282], [395,281], [244,319], [327,317]]\n",
    "pixel_coordinates = [[63, 95], [174, 107], [115, 139], [234, 138], [92, 185], [178, 198], [163, 211], [117, 258], [240, 255], [103, 291], [178, 288]]\n",
    "robot_coordinates = [[393.6,-47.6], [245.8,-29.9], [325.3,11.4], [164.9,7.9], [356.9,73.4], [244.5,92.9], [262.6,107.8], [323.9,170.4], [164.6,168.5], [343.1,215.1], [243.9,212.2]]\n",
    "pixel_points = np.array(pixel_coordinates, dtype=np.float32)\n",
    "robot_points = np.array(robot_coordinates, dtype=np.float32)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(pixel_points, robot_points)\n",
    "print(\"Homography Matrix:\", homography_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d1fea",
   "metadata": {},
   "source": [
    "## pixel to robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_robot(x, y, matrix):\n",
    "    pixel = np.array([x, y, 1]).reshape(3, 1)\n",
    "    robot_coords = np.dot(matrix, pixel)\n",
    "    robot_coords /= robot_coords[2]  \n",
    "    return robot_coords[0][0], robot_coords[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35005d",
   "metadata": {},
   "source": [
    "## Connect to manipulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from xarm.wrapper import XArmAPI\n",
    "\n",
    "\n",
    "arm = XArmAPI('192.168.1.155')\n",
    "arm.motion_enable(enable=True)\n",
    "arm.set_mode(0)\n",
    "arm.set_state(0)\n",
    "arm.connect()\n",
    "arm.move_gohome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e867e",
   "metadata": {},
   "source": [
    "## Trajectory planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957193c0",
   "metadata": {},
   "source": [
    "### box position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6567bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = pixel_to_robot(145, 360, homography_matrix)\n",
    "box_x, box_y = box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49506ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def pick_up_and_drop(x_robot, y_robot):\n",
    "    arm.set_position(x_robot, y_robot, 70)  \n",
    "    arm.set_position(x_robot, y_robot, 18, wait=True)  \n",
    "    arm.set_suction_cup(False)\n",
    "    time.sleep(1)\n",
    "    # arm.set_position(x_robot, y_robot, 16.5, wait=True)  \n",
    "    arm.set_position(x_robot, y_robot, 70, wait=True)  \n",
    "    arm.set_position(box_x, box_y, 200)\n",
    "    arm.set_position(box_x, box_y, 100)\n",
    "    arm.set_suction_cup(True)\n",
    "    arm.set_position(box_x, box_y, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7395a7",
   "metadata": {},
   "source": [
    "## Capture image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow('Webcam Preview - Press Q to capture', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.imwrite('captured_image.jpg', frame)\n",
    "        print(\"Image saved as captured_image.jpg\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c7a25",
   "metadata": {},
   "source": [
    "## Detecting bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fba583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY1\")\n",
    "\n",
    "model_name = \"gemini-2.0-flash\" \n",
    "\n",
    "bounding_box_system_instructions = \"\"\"\n",
    "    Return bounding boxes as a JSON array with labels. Never return masks or code fencing. Limit to 25 objects.\n",
    "    If an object is present multiple times, name them according to their unique characteristic (colors, size, position, unique characteristics, etc..).\n",
    "    \"\"\"\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        threshold=\"BLOCK_ONLY_HIGH\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36028cc",
   "metadata": {},
   "source": [
    "## parse json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(json_output):\n",
    "    # Parsing out the markdown fencing\n",
    "    lines = json_output.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"```json\":\n",
    "            json_output = \"\\n\".join(lines[i+1:])  # Remove everything before \"```json\"\n",
    "            json_output = json_output.split(\"```\")[0]  # Remove everything after the closing \"```\"\n",
    "            break  # Exit the loop once \"```json\" is found\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_groq(json_output):\n",
    "    # Parsing out the markdown fencing\n",
    "    lines = json_output.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"```\":\n",
    "            json_output = \"\\n\".join(lines[i+1:])  # Remove everything before \"```json\"\n",
    "            json_output = json_output.split(\"```\")[0]  # Remove everything after the closing \"```\"\n",
    "            break  # Exit the loop once \"```json\" is found\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740282a9",
   "metadata": {},
   "source": [
    "## Plot bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PIL import ImageColor\n",
    "\n",
    "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "\n",
    "def plot_bounding_boxes(im, bounding_boxes):\n",
    "    \"\"\"\n",
    "    Plots bounding boxes on an image with markers for each a name, using PIL, normalized coordinates, and different colors.\n",
    "\n",
    "    Args:\n",
    "        img_path: The path to the image file.\n",
    "        bounding_boxes: A list of bounding boxes containing the name of the object\n",
    "         and their positions in normalized [y1 x1 y2 x2] format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    img = im\n",
    "    width, height = img.size\n",
    "    print(img.size)\n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Define a list of colors\n",
    "    colors = [\n",
    "    'red',\n",
    "    'green',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'orange',\n",
    "    'pink',\n",
    "    'purple',\n",
    "    'brown',\n",
    "    'gray',\n",
    "    'beige',\n",
    "    'turquoise',\n",
    "    'cyan',\n",
    "    'magenta',\n",
    "    'lime',\n",
    "    'navy',\n",
    "    'maroon',\n",
    "    'teal',\n",
    "    'olive',\n",
    "    'coral',\n",
    "    'lavender',\n",
    "    'violet',\n",
    "    'gold',\n",
    "    'silver',\n",
    "    ] + additional_colors\n",
    "\n",
    "    # Parsing out the markdown fencing\n",
    "    bounding_boxes = parse_json(bounding_boxes)\n",
    "\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Iterate over the bounding boxes\n",
    "    for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
    "      # Select a color from the list\n",
    "      color = colors[i % len(colors)]\n",
    "\n",
    "      # Convert normalized coordinates to absolute coordinates\n",
    "      abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "      abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "      abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "      abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "\n",
    "      if abs_x1 > abs_x2:\n",
    "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "      if abs_y1 > abs_y2:\n",
    "        abs_y1, abs_y2 = abs_y2, abs_y1\n",
    "\n",
    "      # Draw the bounding box\n",
    "      draw.rectangle(\n",
    "          ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
    "      )\n",
    "\n",
    "      # Draw the text\n",
    "      if \"label\" in bounding_box:\n",
    "        draw.text((abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill=color, font=font)\n",
    "\n",
    "    # Display the image\n",
    "    img.save(\"output_image.jpg\")  # or \"output_image.png\"\n",
    "    print(\"Image saved as output_image.jpg\")\n",
    "\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Detect the 2d bounding boxes of the small cubes (with “label” as color of the small cube) outside the brown box\"  # @param {type:\"string\"}\n",
    "\n",
    "image = \"captured_image.jpg\"\n",
    "# Load and resize image\n",
    "im = Image.open(io.BytesIO(open(image, \"rb\").read()))\n",
    "im.thumbnail([1024,1024], Image.Resampling.LANCZOS)\n",
    "\n",
    "# Run model to find bounding boxes\n",
    "response = client.models.generate_content(\n",
    "    model=model_name,\n",
    "    contents=[prompt, im],\n",
    "    config = types.GenerateContentConfig(\n",
    "        system_instruction=bounding_box_system_instructions,\n",
    "        temperature=0.5,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Check output\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73502663",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_boxes(im, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7952ed",
   "metadata": {},
   "source": [
    "## llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa813d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def groq(bounding_boxes):\n",
    "    dotenv.load_dotenv()\n",
    "    print(os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "    # Your Groq API client setup\n",
    "    client = Groq(\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY\")  \n",
    "    )\n",
    "    centroids = []\n",
    "\n",
    "    for i, bounding_box in enumerate(bounding_boxes):\n",
    "\n",
    "        width, height = im.size\n",
    "        # Convert normalized coordinates to absolute coordinates\n",
    "        abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "        abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "        abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "        abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "\n",
    "        if abs_x1 > abs_x2:\n",
    "            abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "        if abs_y1 > abs_y2:\n",
    "            abs_y1, abs_y2 = abs_y2, abs_y\n",
    "        \n",
    "        c1 = (abs_x1 + abs_x2) / 2\n",
    "        c2 = (abs_y1 + abs_y2) / 2\n",
    "        print(c1, c2)\n",
    "\n",
    "        centroids.append({\n",
    "            \"label\": bounding_box[\"label\"],\n",
    "            \"centroid\": [c1, c2]})\n",
    "\n",
    "    custom_prompt = \"pick the blocks in the increasing order of their color intensity\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are an assistant tasked with processing object data and returning only the centroids that match the user's request in JSON format.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"\n",
    "                    Here is a list of objects with their labels and centroids:\n",
    "                    {json.dumps(centroids, indent=2)}\n",
    "\n",
    "                    The command is: \"{custom_prompt}\"\n",
    "\n",
    "                    Please return only the centroids of objects that match this command in this exact JSON format:\n",
    "                    {{\n",
    "                        \"centroids\": [\n",
    "                            {{\n",
    "                                \"centroid\": [x, y]\n",
    "                            }},\n",
    "                            ...\n",
    "                        ]\n",
    "                    }}\n",
    "                    Do not include any explanation or thinking inthe output, only the raw JSON.\n",
    "        \n",
    "                \"\"\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.3-70b-versatile\"\n",
    "    )\n",
    "\n",
    "    print(\"Raw response:\", response)\n",
    "    response_content = response.choices[0].message.content\n",
    "    print(response_content)\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bfaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)\n",
    "parse_json(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(parse_json_groq(response_content))\n",
    "print(result)\n",
    "centroids = result[\"centroids\"]\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5868c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = json.loads(parse_json_groq(response_content))\n",
    "\n",
    "centroids_from_response = result[\"centroids\"]\n",
    "# print(\"Centroids from response:\", type(centroids_from_respo|nse))\n",
    "\n",
    "for centroid in centroids_from_response:\n",
    "    c = centroid[\"centroid\"]\n",
    "    x, y = pixel_to_robot(c[0], c[1], homography_matrix)\n",
    "    pick_up_and_drop(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5294383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = parse_json(response.text)\n",
    "for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
    "\n",
    "    width, height = im.size\n",
    "    # Convert normalized coordinates to absolute coordinates\n",
    "    abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "    abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "    abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "    abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "\n",
    "    if abs_x1 > abs_x2:\n",
    "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "    if abs_y1 > abs_y2:\n",
    "        abs_y1, abs_y2 = abs_y2, abs_y2\n",
    "    \n",
    "    c1 = (abs_x1 + abs_x2) / 2\n",
    "    c2 = (abs_y1 + abs_y2) / 2\n",
    "\n",
    "    c1_robot, c2_robot = pixel_to_robot(c1, c2, homography_matrix)\n",
    "    pick_up_and_drop(c1_robot, c2_robot)\n",
    "arm.move_gohome()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
